{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import *\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "end_month = 202312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = pd.read_feather('../chars_data/chars60_raw_no_impute.feather')\n",
    "char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use All-Stocks value-weighted to calculate EP, DY, LEV, NI, BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vw(df,w,c,g):\n",
    "    df['wc']=df[w]*df[c]\n",
    "    tmp = df.groupby(g)['wc'].sum()/df.groupby(g)[w].sum()\n",
    "    del df['wc']\n",
    "    return tmp\n",
    "\n",
    "lev = vw(char,'me','lev',['date'])*1000 # Leverage (LEV)\n",
    "ep = vw(char,'me','ep',['date'])*1000 # Earnings-to-Price (EP)\n",
    "dy = vw(char,'me','dy',['date'])*1000 # Dividend Yield (DY)\n",
    "ni = vw(char,'me','ni',['date'])*1000 # Net Equity Issues (NI)\n",
    "bm = vw(char,'me','bm',['date'])*1000 # Book-to-Market (BM)\n",
    "\n",
    "mktvars = pd.DataFrame([dy,lev,ep,ni,bm]).T\n",
    "mktvars.columns = ['x_dy','x_lev','x_ep','x_ni','x_bm']\n",
    "mktvars = mktvars.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use 12-months rolling-window mktrf variance to calculate SVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mktrf = pd.read_csv('FF3.csv')\n",
    "# df_mktrf['MKT'] = df_mktrf['MKTRF'] + df_mktrf['RF']\n",
    "# df_mktrf.iloc[:, 1:] = df_mktrf.iloc[:, 1:] / 100\n",
    "# df_mktrf['year'] = df_mktrf['Date'].apply(lambda x: str(x)[0:4])\n",
    "# df_mktrf['month'] = df_mktrf['Date'].apply(lambda x: str(x)[4:6])\n",
    "# df_mktrf['day'] = 1\n",
    "# df_mktrf['date'] = pd.to_datetime(df_mktrf[['year', 'month', 'day']]) + MonthEnd(0)\n",
    "\n",
    "# calc_svar = []\n",
    "# for i in range(df_mktrf.shape[0]):\n",
    "#     if i < 250:\n",
    "#         calc_svar.append(np.nan)\n",
    "#     else:\n",
    "#         temp_df = df_mktrf.iloc[i-250:i, :]\n",
    "#         calc_svar.append(np.var(temp_df['MKT']))\n",
    "\n",
    "# df_mktrf['svar'] = calc_svar\n",
    "# df_mktrf = df_mktrf.sort_values(by=['Date'], ascending=True).reset_index(drop=True)\n",
    "# df_mktrf = df_mktrf[['date', 'svar']]\n",
    "# df_mktrf = df_mktrf.drop_duplicates(subset=['date'], keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Variance (SVAR)\n",
    "dates_filepath = 'FF3.csv'\n",
    "df_mktrf = pd.read_csv(\"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors_daily_CSV.zip\", header=4, index_col=0)\n",
    "df_mktrf = df_mktrf.reset_index().loc[:(df_mktrf.index.tolist().index(df_mktrf.index.tolist()[-1]) - 1)]\n",
    "df_mktrf = df_mktrf.rename(columns={'index': 'Date', 'Mkt-RF':'MKTRF'})\n",
    "# df_mktrf.to_csv(dates_filepath, index=False, encoding=\"utf_8_sig\")\n",
    "\n",
    "df_mktrf['MKT'] = df_mktrf['MKTRF'] + df_mktrf['RF']\n",
    "df_mktrf.iloc[:, 1:] = df_mktrf.iloc[:, 1:].astype(\"float\") / 100\n",
    "df_mktrf['year'] = df_mktrf['Date'].apply(lambda x: str(x)[0:4])\n",
    "df_mktrf['month'] = df_mktrf['Date'].apply(lambda x: str(x)[4:6])\n",
    "df_mktrf['day'] = 1\n",
    "df_mktrf['date'] = pd.to_datetime(df_mktrf[['year', 'month', 'day']]) + MonthEnd(0)\n",
    "\n",
    "month_list = sorted(list(set(df_mktrf['date'])))\n",
    "frame_svar = []\n",
    "for month in month_list:\n",
    "    temp_df = df_mktrf[(df_mktrf.date > month-relativedelta(months=12)) & (df_mktrf.date <= month)]\n",
    "    frame_svar.append(pd.DataFrame([[month, np.var(temp_df['MKT'])]], columns=['date', 'svar']))\n",
    "df_mktrf = pd.concat(frame_svar).reset_index(drop=True)\n",
    "\n",
    "# Merge with previous data\n",
    "df_xt = mktvars.merge(df_mktrf, on=['date'], how='left')\n",
    "df_xt.rename(columns={'svar':'x_svar'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Obtain Illiquidity and Liquidity data from \n",
    "- https://finance.wharton.upenn.edu/~stambaug/liq_data_1962_2023.txt \\\n",
    "--- Column 2: Levels of aggregated liquidity (Figure 1 in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illiquidity (Ill)\n",
    "dates_filepath = 'liquidity.csv'\n",
    "ill = pd.read_csv(\"https://finance.wharton.upenn.edu/~stambaug/liq_data_1962_2023.txt\", header=10, index_col=0).reset_index()\n",
    "ill = ill[ill.columns[0]].str.split('\\t', expand=True)\n",
    "ill.columns = ['Month', 'x_ill', 'Innov Liq (eq8)', 'LIQ', 'Other']\n",
    "ill = ill[['Month', 'x_ill']]\n",
    "# ill.to_csv(dates_filepath)\n",
    "\n",
    "ill['year'] = ill['Month'].apply(lambda x: str(x)[0:4])\n",
    "ill['month'] = ill['Month'].apply(lambda x: str(x)[4:6])\n",
    "ill['day'] = 1\n",
    "ill['date'] = pd.to_datetime(ill[['year', 'month', 'day']]) + MonthEnd(0)\n",
    "ill = ill[['date', 'x_ill']]\n",
    "\n",
    "df_xt = df_xt.merge(ill, on=['date'], how='left')\n",
    "\n",
    "# Liquidity (Liq)\n",
    "df_xt['x_liq'] = df_xt['x_ill'].rolling(12, min_periods=1).mean().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xt.head(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Obtain inflation, TBL, DFY, TMS from FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inflation (INFL)\n",
    "df_cpi = pd.read_csv(\"https://fred.stlouisfed.org/series/CPIAUCSL/downloaddata/CPIAUCSL.csv\", header=0, index_col=0).reset_index().rename(columns={'VALUE':'CPIAUCSL'})\n",
    "df_cpi['date'] = pd.to_datetime(df_cpi['DATE']) + MonthEnd(0)\n",
    "df_cpi['CPIAUCSL_substract'] = df_cpi['CPIAUCSL'].shift(12)\n",
    "df_cpi['x_infl'] = (df_cpi['CPIAUCSL'] - df_cpi['CPIAUCSL_substract']) / df_cpi['CPIAUCSL_substract']\n",
    "df_cpi = df_cpi[['date', 'x_infl']]\n",
    "df_xt = df_xt.merge(df_cpi, on=['date'], how='left')\n",
    "\n",
    "# Treasury-Bill Rate (TBL)\n",
    "df_tbl = pd.read_csv(\"https://fred.stlouisfed.org/series/TB3MS/downloaddata/TB3MS.csv\", header=0, index_col=0).reset_index().rename(columns={'VALUE':'TB3MS'})\n",
    "df_tbl['date'] = pd.to_datetime(df_tbl['DATE']) + MonthEnd(0)\n",
    "df_tbl['x_tbl'] = df_tbl['TB3MS'].astype(float) / 100\n",
    "df_tbl['TB3MS_shift'] = df_tbl['x_tbl'].shift(1)\n",
    "df_tbl['x_deltatbl'] = df_tbl['x_tbl'] - df_tbl['TB3MS_shift']\n",
    "df_xt = df_xt.merge(df_tbl[['date', 'x_tbl', 'x_deltatbl']], on=['date'], how='left')\n",
    "\n",
    "# Default Yield (DFY)\n",
    "df_baa = pd.read_csv(\"https://fred.stlouisfed.org/series/BAA/downloaddata/BAA.csv\", header=0, index_col=0).reset_index().rename(columns={'VALUE':'BAA'})\n",
    "df_aaa = pd.read_csv(\"https://fred.stlouisfed.org/series/AAA/downloaddata/AAA.csv\", header=0, index_col=0).reset_index().rename(columns={'VALUE':'AAA'})\n",
    "df_bondrate = df_baa.merge(df_aaa, on=['DATE'], how='left')\n",
    "df_bondrate['date'] = pd.to_datetime(df_bondrate['DATE']) + MonthEnd(0)\n",
    "df_bondrate['x_dfy'] = (df_bondrate['BAA'] - df_bondrate['AAA']) / 100\n",
    "df_bondrate = df_bondrate[['date', 'x_dfy']]\n",
    "df_xt = df_xt.merge(df_bondrate, on=['date'], how='left')\n",
    "\n",
    "# Term Spread (TMS)\n",
    "df_lty = pd.read_csv(\"https://fred.stlouisfed.org/series/IRLTLT01USM156N/downloaddata/IRLTLT01USM156N.csv\", header=0, index_col=0).reset_index().rename(columns={'VALUE':'IRLTLT01USM156N'})\n",
    "df_lty['date'] = pd.to_datetime(df_lty['DATE']) + MonthEnd(0)\n",
    "df_lty = df_lty.merge(df_tbl, on=['date'], how='left')\n",
    "df_lty['x_tms'] = df_lty['IRLTLT01USM156N'] / 100 - df_lty['x_tbl']\n",
    "df_lty = df_lty[['date', 'x_tms']]\n",
    "df_xt = df_xt.merge(df_lty, on=['date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order data\n",
    "df_xt = df_xt[['date', 'x_ep', 'x_dy', 'x_lev', 'x_ni', 'x_bm', 'x_svar', 'x_ill', 'x_liq', 'x_infl', 'x_tbl', 'x_deltatbl', 'x_dfy', 'x_tms']]\n",
    "df_xt[['x_svar', 'x_ill', 'x_liq', 'x_infl', 'x_tbl', 'x_deltatbl', 'x_dfy', 'x_tms']] = df_xt[['x_svar', 'x_ill', 'x_liq', 'x_infl', 'x_tbl', 'x_deltatbl', 'x_dfy', 'x_tms']].shift(1)\n",
    "df_xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xt.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_list = ['x_ep', 'x_dy', 'x_lev', 'x_ni', 'x_bm', 'x_svar', 'x_ill', 'x_liq', 'x_infl', 'x_tbl', 'x_deltatbl', 'x_dfy', 'x_tms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider Four standardization versions\n",
    "-- 1. No smooth\n",
    "-- 2. Min-Max\n",
    "-- 3. Rolling 10 Years smooth\n",
    "-- 4. Rolling 15 Years smooth\n",
    "-- 5. Rolling 20 Years smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xt[\"x_month\"] = np.arange(1, df_xt.shape[0]+1)/df_xt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_xt = df_xt[df_xt['date'] >= '1959-06-01'].sort_values(by=['date'], ascending=[True]).reset_index(drop=True)\n",
    "df_xt.iloc[:, 1:] = df_xt.iloc[:, 1:].astype(float)\n",
    "df_xt.to_csv(f'xt_{end_month}_nosmooth.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Min-Max standardization\n",
    "xt_minmax = df_xt.copy()\n",
    "for xt in xt_list:\n",
    "    xt_minmax[xt] = (xt_minmax[xt] - np.min(xt_minmax[xt])) / (np.max(xt_minmax[xt]) - np.min(xt_minmax[xt]))\n",
    "\n",
    "xt_minmax.to_csv(f'xt_{end_month}_minmax.csv', index=False, encoding='utf_8_sig')\n",
    "\n",
    "plt.figure(figsize=(25,10))\n",
    "ax1 = plt.subplot(3,5,1);ax1.plot(xt_minmax['x_lev']);ax1.set_title('lev');\n",
    "ax2 = plt.subplot(3,5,2);ax2.plot(xt_minmax['x_ep']);ax2.set_title('ep');\n",
    "ax3 = plt.subplot(3,5,3);ax3.plot(xt_minmax['x_dy']);ax3.set_title('dy');\n",
    "ax4 = plt.subplot(3,5,4);ax4.plot(xt_minmax['x_ni']);ax4.set_title('ni');\n",
    "ax5 = plt.subplot(3,5,5);ax5.plot(xt_minmax['x_ill']);ax5.set_title('ill');\n",
    "ax6 = plt.subplot(3,5,6);ax6.plot(xt_minmax['x_infl']);ax6.set_title('infl');\n",
    "ax7 = plt.subplot(3,5,7);ax7.plot(xt_minmax['x_svar']);ax7.set_title('svar');\n",
    "ax8 = plt.subplot(3,5,8);ax8.plot(xt_minmax['x_dfy']);ax8.set_title('dfy');\n",
    "ax9 = plt.subplot(3,5,9);ax9.plot(xt_minmax['x_tms']);ax9.set_title('tms');\n",
    "ax10=plt.subplot(3,5,10);ax10.plot(xt_minmax['x_tbl']);ax10.set_title('tbl');\n",
    "ax11=plt.subplot(3,5,11);ax11.plot(xt_minmax['x_bm']);ax11.set_title('bm');\n",
    "ax12=plt.subplot(3,5,12);ax12.plot(xt_minmax['x_liq']);ax12.set_title('liq');\n",
    "plt.savefig(\"macro_raw_minmax.pdf\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling 10, 15, 20 Years Percentile Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_standardize(x,w):\n",
    "    '''\n",
    "    x is a list\n",
    "    w is the time window\n",
    "    '''\n",
    "    n = len(x)\n",
    "    # print(n)\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        if i>=w:\n",
    "            h = x[:i][-w:]\n",
    "            s = stats.rankdata(h, \"average\")/len(h)\n",
    "            y.append(s[-1])\n",
    "        elif i>=2:\n",
    "            h = x[:i]\n",
    "            s = stats.rankdata(h, \"average\")/len(h)\n",
    "            y.append(s[-1])\n",
    "        else:\n",
    "            y.append(-2)\n",
    "    return y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_list = [10, 15, 20]\n",
    "for window in window_list:\n",
    "    xt_tmp = df_xt.copy()\n",
    "    for vn in tqdm(xt_list):\n",
    "        # print(vn)\n",
    "        x = list(xt_tmp[vn].values)\n",
    "        w = window * 12\n",
    "        xt_tmp[vn] = quantile_standardize(x,w)\n",
    "    xt_tmp['x_month'] = np.arange(1, xt_tmp.shape[0]+1)\n",
    "    xt_tmp.to_csv(f'xt_{end_month}_{window}y.csv', index=False, encoding='utf_8_sig')\n",
    "\n",
    "    plt.figure(figsize=(25,10))\n",
    "    ax1 = plt.subplot(3,5,1);ax1.plot(xt_tmp['x_lev']);ax1.set_title('lev');\n",
    "    ax2 = plt.subplot(3,5,2);ax2.plot(xt_tmp['x_ep']);ax2.set_title('ep');\n",
    "    ax3 = plt.subplot(3,5,3);ax3.plot(xt_tmp['x_dy']);ax3.set_title('dy');\n",
    "    ax4 = plt.subplot(3,5,4);ax4.plot(xt_tmp['x_ni']);ax4.set_title('ni');\n",
    "    ax5 = plt.subplot(3,5,5);ax5.plot(xt_tmp['x_ill']);ax5.set_title('ill');\n",
    "    ax6 = plt.subplot(3,5,6);ax6.plot(xt_tmp['x_infl']);ax6.set_title('infl');\n",
    "    ax7 = plt.subplot(3,5,7);ax7.plot(xt_tmp['x_svar']);ax7.set_title('svar');\n",
    "    ax8 = plt.subplot(3,5,8);ax8.plot(xt_tmp['x_dfy']);ax8.set_title('dfy');\n",
    "    ax9 = plt.subplot(3,5,9);ax9.plot(xt_tmp['x_tms']);ax9.set_title('tms');\n",
    "    ax10=plt.subplot(3,5,10);ax10.plot(xt_tmp['x_tbl']);ax10.set_title('tbl');\n",
    "    ax11=plt.subplot(3,5,11);ax11.plot(xt_tmp['x_bm']);ax11.set_title('bm');\n",
    "    ax12=plt.subplot(3,5,12);ax12.plot(xt_tmp['x_liq']);ax12.set_title('liq');\n",
    "    plt.savefig(f\"macro_raw_{window}y.pdf\",bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_tmp[xt_tmp]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2937e43c46ad06112ed725122b0ed48d060797516f91e658e2dc1f8d1b2ee403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
